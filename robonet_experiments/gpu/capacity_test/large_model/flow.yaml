# example configuration file for training a set of video prediction model on sawyer data from RoboNet
# each model is trained on a different fraction of data

# general experiment configurations
batch_size: 16
train_class: VPredTrainable 
max_steps: 500000
train_fraction: 0.9

# list of dictionaries containing data sources along with filter parameters
batch_config:
  # selects sawyer data with autograsp enabled (adim=4, robot=sawyer)
  - data_directory: ${DATA_DIR}/hdf5
    robot: search/grid(["sawyer", ["sawyer", "franka"], ["sawyer", "baxter"], ["sawyer", "baxter", "franka"]])
    adim: 4

# loader_hparams used to initialize loader object
loader_hparams:
  dataset: "RoboNet"
  buffer_size: 10
  color_augmentation: 0.1
  load_T: 15

# model_hparams used to create graph and loss function
model_hparams:
  model: deterministic
  graph_type: vgg_conv
  lr: 0.0001
  context_frames: 5
  schedule_sampling_k: 4000
  use_flows: True
  tv_weight: 0
  enc_filters: [512, 1024, 1536]
  lstm_filters: 1536
  dec_filters: [1024, 512]
  img_flows: 32        
  skip_flows: 16

